{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bempong-Sylvester-Obese/RSNA-Intracranial-Aneurysm-Detection/blob/main/Mean_Weighted_Columnwise_AUCROC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Calculates the weighted macro-average Area Under Curve Receiver Operating Characteristic (AUCROC) score.\n",
        "This metric generalizes the `roc_auc_score` with `average='macro'` by allowing user-defined class weights.\n",
        "\"\"\"\n",
        "from typing import List, Optional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def score(\n",
        "    solution: pd.DataFrame,\n",
        "    submission: pd.DataFrame,\n",
        "    row_id_column_name: str,\n",
        "    class_weights: Optional[List[float]] = None,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calculates the weighted macro-average AUCROC score.\n",
        "\n",
        "    This metric generalizes the `roc_auc_score` with `average='macro'` by allowing user-defined class weights.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    solution : pd.DataFrame\n",
        "        DataFrame containing the true labels.\n",
        "    submission : pd.DataFrame\n",
        "        DataFrame containing the predicted scores.\n",
        "    row_id_column_name : str\n",
        "        The name of the column containing the row IDs.\n",
        "    class_weights : Optional[List[float]], default=None\n",
        "        A list of weights for each class. If None, all classes are weighted equally.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The weighted multi-label AUC score.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> # Test for perfect predictions.\n",
        "    >>> solution = pd.DataFrame({'id': [1, 2, 3], 'cat': [1, 0, 1], 'dog': [0, 1, 1]})\n",
        "    >>> submission = pd.DataFrame({'id': [1, 2, 3], 'cat': [0.9, 0.2, 0.8], 'dog': [0.1, 0.7, 0.6]})\n",
        "    >>> score(solution.copy(), submission.copy(), 'id')\n",
        "    1.0\n",
        "\n",
        "    >>> score(solution.copy(), submission.copy(), 'id', class_weights=[0.25, 0.75])\n",
        "    1.0\n",
        "\n",
        "    >>> # Test weighting.\n",
        "    >>> solution = pd.DataFrame({'id': [1, 2, 3, 4], 'A': [0, 0, 1, 1], 'B': [0, 0, 1, 1]})\n",
        "    >>> submission = pd.DataFrame({'id': [1, 2, 3, 4], 'A': [0.1, 0.2, 0.8, 0.9], 'B': [0.8, 0.2, 0.1, 0.9]})\n",
        "    >>> # Here, the AUC for class 'A' is 1.0 and for class 'B' is 0.5.\n",
        "    >>> # The unweighted macro-average is (1.0 + 0.5) / 2 = 0.75.\n",
        "    >>> score(solution.copy(), submission.copy(), 'id')\n",
        "    0.75\n",
        "\n",
        "    >>> # Using weights to prioritize the better-performing class 'A'.\n",
        "    >>> # The weighted average is (1.0 * 0.75) + (0.5 * 0.25) = 0.875.\n",
        "    >>> score(solution.copy(), submission.copy(), 'id', class_weights=[3, 1])\n",
        "    0.875\n",
        "\n",
        "    >>> # Using weights to prioritize the worse-performing class 'B'.\n",
        "    >>> # The weighted average is (1.0 * 0.25) + (0.5 * 0.75) = 0.625.\n",
        "    >>> score(solution.copy(), submission.copy(), 'id', class_weights=[1, 3])\n",
        "    0.625\n",
        "    \"\"\"\n",
        "    # don't use the row_id_column\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    # Validate that all submission columns are numeric\n",
        "    for col in submission.columns:\n",
        "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
        "            raise ParticipantVisibleError(f'Submission column {col} must be numeric.')\n",
        "\n",
        "    # Validate that the number of columns match\n",
        "    if len(solution.columns) != len(submission.columns):\n",
        "        raise ParticipantVisibleError(\n",
        "            'Submission must have predictions for every class.'\n",
        "        )\n",
        "\n",
        "    return float(\n",
        "        weighted_multilabel_auc(solution.values, submission.values, class_weights)\n",
        "    )\n",
        "\n",
        "\n",
        "def weighted_multilabel_auc(\n",
        "    y_true: np.ndarray,\n",
        "    y_scores: np.ndarray,\n",
        "    class_weights: Optional[List[float]] = None,\n",
        ") -> float:\n",
        "    \"\"\"Compute weighted AUC for multilabel classification.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : np.ndarray of shape (n_samples, n_classes)\n",
        "        True binary labels (0 or 1) for each class\n",
        "    y_scores : np.ndarray of shape (n_samples, n_classes)\n",
        "        Target scores (probability estimates or decision values)\n",
        "    class_weights : array-like of shape (n_classes,), optional\n",
        "        Weights for each class. If None, uniform weights are used.\n",
        "        Weights will be normalized to sum to 1.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    weighted_auc : float\n",
        "        The weighted average AUC\n",
        "\n",
        "    Raises:\n",
        "    -------\n",
        "    ValueError\n",
        "        If any class does not have both positive and negative samples\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_scores = np.asarray(y_scores)\n",
        "    n_classes = y_true.shape[1]\n",
        "\n",
        "    # Get AUC for each class\n",
        "    try:\n",
        "        individual_aucs = roc_auc_score(y_true, y_scores, average=None)\n",
        "    except ValueError:\n",
        "        raise ParticipantVisibleError(\n",
        "            'AUC could not be calculated from given predictions.'\n",
        "        ) from None\n",
        "\n",
        "    # Handle weights\n",
        "    if class_weights is None:  # Uniform weights\n",
        "        weights_array = np.ones(n_classes)\n",
        "    else:\n",
        "        weights_array = np.asarray(class_weights)\n",
        "\n",
        "    # Check weight dimensions\n",
        "    if len(weights_array) != n_classes:\n",
        "        raise ValueError(\n",
        "            f'Number of weights ({len(weights_array)}) must match '\n",
        "            f'number of classes ({n_classes})'\n",
        "        )\n",
        "\n",
        "    # Check for non-negative weights\n",
        "    if np.any(weights_array < 0):\n",
        "        raise ValueError('All class weights must be non-negative')\n",
        "\n",
        "    # Check that at least one weight is positive\n",
        "    if np.sum(weights_array) == 0:\n",
        "        raise ValueError('At least one class weight must be positive')\n",
        "\n",
        "    # Normalize weights to sum to 1\n",
        "    weights_array = weights_array / np.sum(weights_array)\n",
        "\n",
        "    # Compute weighted average\n",
        "    return np.sum(individual_aucs * weights_array)"
      ],
      "metadata": {
        "_uuid": "2a1239f3-55fc-4dbb-9d3a-e90bfffa038c",
        "_cell_guid": "4cf02a6f-b7e9-4360-892d-b1a50793eb12",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "yoBzXs4JzBy7"
      },
      "outputs": [],
      "execution_count": 5
    }
  ]
}